{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "class Extractor():\n",
    "    def __init__(self, weights=None):\n",
    "        \"\"\"Either load pretrained from imagenet, or load our saved\n",
    "        weights from our own training.\"\"\"\n",
    "\n",
    "        self.weights = weights  # so we can check elsewhere which model\n",
    "\n",
    "        if weights is None:\n",
    "            # Get model with pretrained weights.\n",
    "            base_model = InceptionV3(\n",
    "                weights='imagenet',\n",
    "                include_top=True\n",
    "            )\n",
    "\n",
    "            # We'll extract features at the final pool layer.\n",
    "            self.model = Model(\n",
    "                inputs=base_model.input,\n",
    "                outputs=base_model.get_layer('avg_pool').output\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Load the model first.\n",
    "            self.model = load_model(weights)\n",
    "\n",
    "            # Then remove the top so we get features not predictions.\n",
    "            # From: https://github.com/fchollet/keras/issues/2371\n",
    "            self.model.layers.pop()\n",
    "            self.model.layers.pop()  # two pops to get to pool layer\n",
    "            self.model.outputs = [self.model.layers[-1].output]\n",
    "            self.model.output_layers = [self.model.layers[-1]]\n",
    "            self.model.layers[-1].outbound_nodes = []\n",
    "\n",
    "    def extract(self, image_path):\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = self.model.predict(x)\n",
    "\n",
    "        if self.weights is None:\n",
    "            # For imagenet/default network:\n",
    "            features = features[0]\n",
    "        else:\n",
    "            # For loaded network:\n",
    "            features = features[0]\n",
    "\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "from data import DataSet\n",
    "from extractor import Extractor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set defaults.\n",
    "seq_length = 40\n",
    "class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n",
    "\n",
    "# Get the dataset.\n",
    "data = DataSet(seq_length=seq_length, class_limit=class_limit)\n",
    "\n",
    "# get the model.\n",
    "model = Extractor()\n",
    "\n",
    "# Loop through data.\n",
    "pbar = tqdm(total=len(data.data))\n",
    "for video in data.data:\n",
    "\n",
    "    # Get the path to the sequence for this video.\n",
    "    path = os.path.join('data', 'sequences', video[2] + '-' + str(seq_length) + \\\n",
    "        '-features')  # numpy will auto-append .npy\n",
    "\n",
    "    # Check if we already have it.\n",
    "    if os.path.isfile(path + '.npy'):\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # Get the frames for this video.\n",
    "    frames = data.get_frames_for_sample(video)\n",
    "\n",
    "    # Now downsample to just the ones we need.\n",
    "    frames = data.rescale_list(frames, seq_length)\n",
    "\n",
    "    # Now loop through and extract features to build the sequence.\n",
    "    sequence = []\n",
    "    for image in frames:\n",
    "        features = model.extract(image)\n",
    "        sequence.append(features)\n",
    "\n",
    "    # Save the sequence.\n",
    "    np.save(path, sequence)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for managing our data.\n",
    "\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import operator\n",
    "import threading\n",
    "#from processor import process_image\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\"\"\"\n",
    "Process an image that we can pass to our networks.\n",
    "\"\"\"\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataSet():\n",
    "\n",
    "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
    "        \"\"\"Constructor.\n",
    "        seq_length = (int) the number of frames to consider\n",
    "        class_limit = (int) number of classes to limit the data to.\n",
    "            None = no limit.\n",
    "        \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.class_limit = class_limit\n",
    "        self.sequence_path = os.path.join('data', 'sequences')\n",
    "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
    "\n",
    "        # Get the data.\n",
    "        self.data = self.get_data()\n",
    "\n",
    "        # Get the classes.\n",
    "        #self.classes = self.get_classes()\n",
    "\n",
    "        # Now do some minor data cleaning.\n",
    "        self.data = self.clean_data()\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "        \n",
    "    def process_image(image, target_shape):\n",
    "        \"\"\"Given an image, process it and return the array.\"\"\"\n",
    "        # Load the image.\n",
    "        h, w, _ = target_shape\n",
    "        image = load_img(image, target_size=(h, w))\n",
    "\n",
    "        # Turn it into numpy, normalize and return.\n",
    "        img_arr = img_to_array(image)\n",
    "        x = (img_arr / 255.).astype(np.float32)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_data():\n",
    "        \"\"\"Load our data from file.\"\"\"\n",
    "        with open(os.path.join('data', 'data_file.csv'), 'r') as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            data = list(reader)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def clean_data(self):\n",
    "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
    "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
    "        data_clean = []\n",
    "        for item in self.data:\n",
    "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
    "                    and item[1] in self.classes:\n",
    "                data_clean.append(item)\n",
    "\n",
    "        return data_clean\n",
    "\n",
    "    def get_frames_for_sample(sample):\n",
    "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
    "        filenames.\"\"\"\n",
    "        path = os.path.join('data', sample[0], sample[1])\n",
    "        filename = sample[2]\n",
    "        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
    "        return images\n",
    "\n",
    "\n",
    "    def get_filename_from_image(filename):\n",
    "        parts = filename.split(os.path.sep)\n",
    "        return parts[-1].replace('.jpg', '')\n",
    "\n",
    "\n",
    "    def rescale_list(input_list, size):\n",
    "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
    "        if we want a list of size 5 and we have a list of size 25, return a new\n",
    "        list of size five which is every 5th element of the origina list.\"\"\"\n",
    "        assert len(input_list) >= size\n",
    "\n",
    "        # Get the number to skip between iterations.\n",
    "        skip = len(input_list) // size\n",
    "\n",
    "        # Build our new output.\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "        # Cut off the last one if needed.\n",
    "        return output[:size]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
